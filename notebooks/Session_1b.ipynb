{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to vector and raster data manipulation with `geopandas` and `rasterio`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will borrow heavily from the NCEAS/Arctic Data Center [workshop material](https://learning.nceas.ucsb.edu/2022-09-arctic/sections/10-geopandas.html)!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go exploring on the Arctic Data Center's [catalog](https://arcticdata.io/catalog/data)! I searched for `.tif` files and found a dataset from Berner, L.T., P. Jantz, K.D. Tape, and S.J. Goetz. 2018. Tundra plant above-ground biomass and shrub dominance mapped across the North Slope of Alaska. Environmental Research Letters. 13(3):035002. https://doi.org/10.1088/1748-9326/aaaa9a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import numpy as np\n",
    "import numpy.ma as ma # numpy mask module\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install rasterio\n",
    "import rasterio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Raster data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are going to pull data directly off of the Arctic Data Center's repository. The URL is for the data entry, which is the first argument in  `urlretrieve`, and the second argument is the specific file to be downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://cn.dataone.org/cn/v2/resolve/urn:uuid:8233336b-0b1c-4809-b01e-4786f26db63a'\n",
    "\n",
    "msg = urllib.request.urlretrieve(url, \"shrub_dominance_of_agb_p50.tif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the `.tif` we just downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=200)\n",
    "with rasterio.open(\"shrub_dominance_of_agb_p50.tif\", masked=True) as shrub_dom:\n",
    "    # read in raster (1st band)\n",
    "    shrub_arr = shrub_dom.read(1)\n",
    "    shrub_arr = ma.masked_where(shrub_arr == shrub_dom.nodata, shrub_arr)\n",
    "    # shrub_arr = shrub_arr\n",
    "    shrub_meta = shrub_dom.profile\n",
    "\n",
    "im0 = ax.imshow(shrub_arr)\n",
    "cb = fig.colorbar(im0, ax=ax, label=\"shrub dominance (shrub/plant AGB)\",  orientation='horizontal', fraction=0.04, pad=0.2)\n",
    "print(shrub_meta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on here?\n",
    "- we instantiated a `fig` and `ax` object\n",
    "- we used `numpy.ma` to mask out the nodata values (which are 255.0)\n",
    "- we printed out the metadata for the raster\n",
    "- we used `imshow()` on the `ax` object to display the values of the array \n",
    "- the axes have an origin at the bottom left of (0,0) because we did not provide `imshow` an `extent`, which we will see later, that can put the x and y axes in real space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FWIW I think there is maybe some issue here, I feel like there should be more data than the nodata mask implies...whatever, go check out the [original work](https://iopscience.iop.org/article/10.1088/1748-9326/aaaa9a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: vector data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's look at vector data. I have already downloaded for you the Circum-Arctic permafrost extent map from the NSIDC [here](https://nsidc.org/data/ggd318/versions/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permafrost = gpd.read_file(\"../arctic-data/permaice.shp\")\n",
    "\n",
    "permafrost.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform this to the [coordinate reference system](https://geopandas.org/en/stable/docs/user_guide/projections.html) that our raster is in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permafrost = permafrost.to_crs(\"EPSG:3338\")\n",
    "\n",
    "permafrost.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that geopandas is pretty good at reprojecting, but man are conical polar projections tricky math! If you go right to pseudo-Mercator from a polar projection, you'll smear these shapefiles across the Arctic. Instead, let's clip the permafrost shapefile to the extent of our shrub dominance raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(\"shrub_dominance_of_agb_p50.tif\", masked=True) as shrub_dom:\n",
    "    # Use Shapely to make a box geodataframe object from the bounds of the raster\n",
    "    bbox = box(shrub_dom.bounds[0], shrub_dom.bounds[1], shrub_dom.bounds[2], shrub_dom.bounds[3])\n",
    "    coord_box_df = gpd.GeoDataFrame(crs = 'EPSG:3338',geometry = [bbox])\n",
    "\n",
    "# ...and then clip to it!\n",
    "\n",
    "permafrost_clip = permafrost.clip(coord_box_df)\n",
    "\n",
    "permafrost_clip.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, but this blue is boring. What is even in this object anyway?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permafrost_clip.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right, geopandas GeoDataFrames are just dataframes with some spatial info! We can look at the columns to see attributes for the shapefiles. \"COMBO\" is the three letter combination of permafrost extent, ice content, and overburden (soil) thickness. Read the user manual [here](https://nsidc.org/sites/default/files/ggd318-v002-userguide.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permafrost_clip.plot(column=\"COMBO\", legend=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: together!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rasterio.plot.show(src)` can plot raster data. But rasters are just grids (or arrays) of numbers. If you tell `plt.imshow()` the extent (boundaries) of the image (the data array), you can transform your raster data however you want, and you can plot it with vector data as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "with rasterio.open(\"shrub_dominance_of_agb_p50.tif\", masked=True) as shrub_dom:\n",
    "    shrub_arr = shrub_dom.read(1)\n",
    "    shrub_arr = ma.masked_where(shrub_arr == shrub_dom.nodata, shrub_arr)\n",
    "    # Don't you love how \"extent\" coordinates need to be in a different order? :upside-down smiley face:\n",
    "    extent=[shrub_dom.bounds[0], shrub_dom.bounds[2], shrub_dom.bounds[1], shrub_dom.bounds[3]]\n",
    "    im0 = ax.imshow(shrub_arr,\n",
    "    extent=extent,\n",
    "    # vmin=0.0,\n",
    "    # vmax=1.0,\n",
    "    cmap=\"binary_r\",\n",
    "    zorder=0,\n",
    "    )\n",
    "\n",
    "    shape = permafrost_clip.plot(column=\"COMBO\", legend=True, alpha=0.5, zorder=2, ax=ax)\n",
    "\n",
    "cb = fig.colorbar(im0, ax=ax, label=\"shrub dominance (shrub/plant AGB)\",  orientation='horizontal', fraction=0.04, pad=0.1)\n",
    "\n",
    "fig.tight_layout()\n",
    "# Note I am being a bad data visualizer because white is both 100 and nodata. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Split-apply-combine raster data with vector data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to analyze raster data grouped by vector data properties? The strategy we have here is to [`rasterize`](https://rasterio.readthedocs.io/en/latest/api/rasterio.features.html#rasterio.features.rasterize) our vector data - instead of having polygons with certain properties, we're going to create arrays where there is one value \"under\" the polygon of interest and another value (0, or null) everywhere else"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get the necessary data and metadata from our raster of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rasterio import features\n",
    "\n",
    "with rasterio.open(\"shrub_dominance_of_agb_p50.tif\", masked=True) as shrub_dom:\n",
    "\n",
    "    shrub_meta = shrub_dom.profile\n",
    "    shrub_arr = shrub_dom.read(1)\n",
    "    shrub_arr = ma.masked_where(shrub_arr == shrub_dom.nodata, shrub_arr)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is a great time to [`dissolve`](https://geopandas.org/en/stable/docs/user_guide/aggregation_with_dissolve.html) our polygons based on their `COMBO` values so that we are rasterizing all the values we are interested in at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permafrost_clip = permafrost_clip.dissolve(by='COMBO').reset_index()\n",
    "# resetting the index helps us iterate through the geometries in the next step, though note each NUM_CODE is unique to the COMBO\n",
    "permafrost_clip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to instantiate two [dictionaries](https://docs.python.org/3/tutorial/datastructures.html) to store the resulting data arrays. Joanmarie will elaborate in the workshop but basically you don't want to store lists or arrays in pandas dataframes. Your goal is to store big raw datasets in dictionaries, reduce them, and then stick them back into your dataframe when all is said and done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_dict = {}\n",
    "raw_values_dict = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we shall (1) rasterize our polygons, (2) make a mask over the raster where the polygon value is present, and both (3) store that raw masked array and (4) calculate the mean of that masked array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for geom, idx in zip(permafrost_clip['geometry'], permafrost_clip.index):\n",
    "    # I spent WAY too much time messing around with this part, you apparently can't just\n",
    "    # give rasterize a polygon, it has to either be a MutliPolygon or a list of geometries\n",
    "    # This code does the latter, and the Arctic Data Center tutorial's only works because their\n",
    "    # example vector data is accidentally multipolygons, but our data has a polygon\n",
    "    geom = shape(geom)\n",
    "    geoms = [(geom, 1)]\n",
    "    # Now this looks like the ADC example\n",
    "    rasterized = features.rasterize(\n",
    "                                    geoms,\n",
    "                                    out_shape=shrub_arr.shape, # Look like the source raster\n",
    "                                    transform=shrub_meta['transform'], # Have the geometry of the source raster\n",
    "                                    all_touched=True # all pixels touched by geometries (as opposed to pixel centers)\n",
    "                                    )\n",
    "    # Theoretically instead of individually rasterizing each polygon type\n",
    "    # You could rasterize the whole thing and instead of 0s and 1s you can\n",
    "    # make the raster value the index and then do basic array-style analyses\n",
    "    # Maybe I can offer treats to someone who writes that for me...\n",
    "    r_index = np.where(rasterized == 1) # Make the mask\n",
    "    # r_index.filled(np.nan)\n",
    "    raw_values_dict[idx] = shrub_arr[r_index].compressed() # store all non-masked data (the compressed thing)\n",
    "    means_dict[idx] = np.nanmean(shrub_arr[r_index].compressed()) # calculate the mean of the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dictionary whose keys are the index and the values are the means of the masked arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Whenever I say \"masked array\" I always think of:*\n",
    "\n",
    "![masquerade](https://media.tenor.com/FTk5tv3gF9MAAAAC/musical-phantom-of-the-opera.gif \"masquerade\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But I also made a dictionary that stored *all* of the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_values_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe you want to do further analyses on the data that you don't want to reduce in that loop. For example, maybe you want to set a threshold number of pixels before you allow for a mean to be counted? This is relevant in this example where the polygon for \"ocean\" has some data in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len is length of the array, or number of unmasked pixels \n",
    "{key: len(value) for key, value in raw_values_dict.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just create a data frame from that dictionary, and join it to the vector data using `pandas` operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# create a data frame from the result\n",
    "means_df = pd.DataFrame.from_dict(means_dict,\n",
    "                                     orient='index',\n",
    "                                     columns=['mean_shrub'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`pd.DataFrame.merge()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) is a common and powerful way to join two dataframes that share common columns or indices (the latter is true in our case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perma_data = permafrost_clip.merge(means_df,\n",
    "                                    left_index=True,\n",
    "                                    right_index=True,\n",
    "                                    how='inner')\n",
    "\n",
    "perma_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a map! I took some inspiration for treating missing data from the [GeoPandas docs](https://geopandas.org/en/stable/docs/user_guide/mapping.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "res = perma_data.plot(column=\"mean_shrub\",\n",
    "                        legend=True,\n",
    "                        legend_kwds={'label': \"Shrub dominance (shrub/plant AGB)\",\n",
    "                        'orientation': \"horizontal\"},\n",
    "                        missing_kwds={\n",
    "                        \"color\": \"lightgrey\",\n",
    "                        \"edgecolor\": \"red\",\n",
    "                        \"hatch\": \"///\",\n",
    "                        \"label\": \"No values\",\n",
    "                        },\n",
    "                        ax=ax\n",
    "                        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yeah, maybe you'd write a lil script that turns data into NaNs if the threshold is below a certain number...or you just decide to go in and get rid of the data in the ocean. :shrug:\n",
    "Of course this analysis is a little meaningless as the polygons are huge, but you can see how this would work!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to just install and use [`rasterstats`](https://github.com/perrygeo/python-rasterstats/tree/d188eaf1f1c20c3ef33aad407f55f9fce51a1220), whose source code I have stolen to write the above snippets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A note: point data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, you can use `rasterio` and `geopandas` to [sample](https://rasterio.readthedocs.io/en/latest/api/rasterio.sample.html) point data. A good example can be found in the [GeoPandas docs](https://geopandas.org/en/stable/gallery/geopandas_rasterio_sample.html). If you want to sample an area around a point, consider employing a [buffer](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoSeries.buffer.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon prompt:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between the Arctic Data Center, the [National Snow and Ice Data Center](https://nsidc.org/home), the [Arctic Permafrost Geospatial Centre](https://apgc.awi.de/), and others, there are so many vector and raster datasets to cross-analyze! Go do some science. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neukom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4496227e9e35a1cad8f46d1878e766ce3696b74827c1cccb91d7e0ed1733d2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
