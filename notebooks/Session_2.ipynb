{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Earth Engine and its pal `geemap`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully Earth Engine needs no introduction, but it is a daunting resource both from a data and coding perspective. In addition to accessing Earth Engine via the code editor, Earth Engine has a [Python API](https://developers.google.com/earth-engine/tutorials/community/intro-to-python-api). Most function calls are identical, and both exploit [client- and server-side functions](https://developers.google.com/earth-engine/guides/client_server), which can be confusing as it is different than what we were doing in Session 1. \n",
    "\n",
    "Although GEE has some built-in data analysis and viz functions, our lord and savior Qiusheng Wu created [`geemap`](https://geemap.org/) to supplement the GEE Python API to help users familiar with Python data exploration and visualization tools. \n",
    "\n",
    "Your best workflow really comes down to what you are most comfortable doing - most StackExchange answers are either about the GEE JavaScript API or the Python geospatial stack, so if you want to use the two together, your best bet is leveraging `geemap` functions to get data in a format with which you are most comfortable /hottake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import ee\n",
    "\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following commands must be called each time you start a new kernel. Make sure to open the link in a browser profile that has an account with Earth Engine access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get shapefiles into Earth Engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going back to our oldy but a goodie permafrost map. Let's see what this looks like, and its crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permafrost = gpd.read_file(\"../arctic-data/permaice.shp\")\n",
    "\n",
    "pf_filtered = permafrost.dropna(subset=['EXTENT'])\n",
    "\n",
    "pf_filtered.plot(column='COMBO', legend=True)\n",
    "print(pf_filtered.crs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`geemaps`'s [documentation](https://geemap.readthedocs.io/en/latest/readme.html) lists all the great functions we can use, including a function that converts [`ee.FeatureCollection`s](https://developers.google.com/earth-engine/guides/feature_collections) to shapefiles.  \n",
    "\n",
    "Here I am just going to grab the outline of Alaska - I'm sure it lives somewhere easy on one of these Arctic databases, but this was easiest for me and demonstrates an Earth Engine tool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alaska = geemap.ee_to_shp(\n",
    "    ee.FeatureCollection('TIGER/2016/States').filter(ee.Filter.eq('NAME', 'Alaska')),\n",
    "    filename='../arctic-data/alaska.shp'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do this because you have to do a bunch of stupid `.map()` functions in the Earth Engine API to clip two complex shapefiles to each other, but GeoPandas makes it easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is commented out because it definitely works but the OG permafrost shapefile was super weird when it got projected to pseudo-Mercator\n",
    "# permafrost = geemap.shp_to_ee(\n",
    "#     os.path.join(os.path.dirname(os.getcwd()),\"./arctic-data/alaska_permafrost.shp\"),\n",
    "#      )\n",
    "# permafrost_geoms = permafrost.map(lambda feature: feature.geometry())\n",
    "# perma_clip = alaska.map(lambda feature: feature.intersection(permafrost_geoms, 1)); # 1 refers to the maxError argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alaska = gpd.read_file(\"../arctic-data/alaska.shp\").to_crs(pf_filtered.crs) # I think it came that way actually\n",
    "permafrost_clipped = pf_filtered.clip(alaska)\n",
    "\n",
    "# Note this is EXTREMELY efficient. You'd have to map over individual geometries in Earth Engine "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our result in the WGS84 projection (a file downloaded from Earth Engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permafrost_clipped.to_crs('EPSG:4326').plot(column='COMBO')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, so let's also save that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permafrost_clipped.to_crs('EPSG:4326').to_file(\"../arctic-data/alaska_permafrost.shp\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now bring your newly clipped dataset into Earth Engine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permafrost = geemap.shp_to_ee(\n",
    "    \"../arctic-data/alaska_permafrost.shp\"\n",
    "     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`geemap` has a `Map()` tool that resembles the API of the JavaScript code editor. One thing is that if you add a layer to a map in one line, the whole Notebook's Map() instances will update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "Map.addLayer(permafrost, {}, 'permafrost')\n",
    "Map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with HydroSHED watershed boundaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earth Engine stores lots of vector data in addition to raster data, like the [HydroSHEDS](https://developers.google.com/earth-engine/datasets/tags/hydrosheds) global watershed delineation dataset. Since Earth Engine doesn't allow you to route flow or delineate watersheds on its servers, this is the best we get besides delineating our own watersheds and importing them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headwater_sheds = (\n",
    "    ee.FeatureCollection(\"WWF/HydroSHEDS/v1/Basins/hybas_10\") # Level 10 sheds are usually the smallest watershed units\n",
    "    .filter(ee.Filter.equals(leftField = 'SUB_AREA', rightField = 'UP_AREA')) # this filter makes sure the watersheds represent the headwaters - they have no extra upstream drainage area\n",
    "    .filterBounds(ee.FeatureCollection('TIGER/2016/States').filter(ee.Filter.eq('NAME', 'Alaska'))) # and only look at watersheds in ALaska\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(headwater_sheds, {}, 'headwater sheds')\n",
    "Map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define key functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the client and server side functions? [`imageCollection.map()`](https://developers.google.com/earth-engine/guides/ic_mapping) is the powerful server-side function that applies a function to every item in a collection. It's kind of like the reverse syntax of a `for` loop where you do `image.map(function)`. \n",
    "\n",
    "Here are some function I'll use in the upcoming analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer the temporal metadata from each satellite image\n",
    "\n",
    "def createTimeBand(image):\n",
    "  return image.addBands(image.metadata('system:time_start').divide(3.154e10));\n",
    "  # // Scale is now in years\n",
    "  # // in the linear regression output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce an annual reduction of some ImageCollection (e.g. max NDVI for the year for 20 years, resulting in 20 images)\n",
    "\n",
    "def annual_images(y): # y is a list of years \n",
    "    range_year = ee.Filter.calendarRange(y, y, 'year')\n",
    "    range_month = ee.Filter.calendarRange(start_month, end_month, 'month')\n",
    "    filtered_dataset = (index_collection\n",
    "                        .filter(range_year)\n",
    "                        .filter(range_month)\n",
    "                        .map(createTimeBand)) # Needed for linear regression \n",
    "    # Combine the mean and standard deviation reducers.\n",
    "    if analysis == 'mean':\n",
    "      reducers = ee.Reducer.mean().combine(\n",
    "        reducer2=ee.Reducer.stdDev(),\n",
    "        sharedInputs=True\n",
    "      )\n",
    "    elif analysis == 'min' or analysis == 'max':\n",
    "      reducers = ee.Reducer.mean().combine(\n",
    "        reducer2=ee.Reducer.minMax(),\n",
    "        sharedInputs=True\n",
    "      )\n",
    "    elif analysis == 'median':\n",
    "      reducers = ee.Reducer.mean().combine(\n",
    "        reducer2=ee.Reducer.median(),\n",
    "        sharedInputs=True\n",
    "      )\n",
    "\n",
    "# Use the combined reducer to get the mean and SD of the image.\n",
    "    stats0 = filtered_dataset.reduce(\n",
    "      reducer=reducers,\n",
    "    )\n",
    "\n",
    "    return stats0.set('year',y)\n",
    "\n",
    "# adapted from https://gis.stackexchange.com/questions/392834/transform-google-earth-engine-script-to-python-with-landsat-8-temporal-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIS-specific functions\n",
    "\n",
    "# Mask out water\n",
    "def maskWater(image):\n",
    "    return image.updateMask(waterMask.select('water_mask').lt(1));\n",
    "\n",
    "def scale_factor(image):\n",
    "# scale factor for the MODIS MOD13Q1 product\n",
    "    return image.multiply(0.0001).copyProperties(image, ['system:time_start'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example analysis: get pixelwise annual trend in maximum NDVI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read about the MODIS product [here](https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MOD13Q1#description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIS water mask is probably universally good to apply to all imagery (if you want to mask water!)\n",
    "waterMask = ee.ImageCollection('MODIS/006/MOD44W').filter(ee.Filter.date('2015-01-01', '2015-01-02')).select('water_mask').first();\n",
    "\n",
    "# This dataset is a composite that chooses the best-quality pixels\n",
    "# per 16-day period, so no cloud masking is required.\n",
    "ndvi_raw = ee.ImageCollection('MODIS/006/MOD13Q1').select('NDVI')\n",
    "ndvi = ndvi_raw.map(maskWater).map(scale_factor);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I wrote an easy-to-adjust codeblock for making those annual image collections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options are 'mean', 'median', 'min' 'max'\n",
    "analysis = 'max'\n",
    "\n",
    "start_year=2000\n",
    "end_year=2022\n",
    "start_month=6\n",
    "end_month=9\n",
    "index_collection = ndvi\n",
    "\n",
    "# Options are 'mean_std', 'mean_min_max', and 'median'\n",
    "# I want to replace this with the \"analysis\" variable \n",
    "#reducer='mean_min_max'\n",
    "\n",
    "years = ee.List.sequence(start_year,end_year)\n",
    "\n",
    "yearwise_ndvi = years.map(annual_images)\n",
    "\n",
    "# Make an ImageCollection from the list of images you just composited,\n",
    "# since you need an ImageCollection for the linear fit reduction\n",
    "yearCompCol = ee.ImageCollection.fromImages(yearwise_ndvi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may note that this takes no time to run, which seems wild, right? Turns out two things are happening:\n",
    "1. Google's computers are huge so any server-side calculation will get paralellized and run quickly, but more importantly\n",
    "2. You actually haven't calculated anything yet because everything is stil server-side. Google will only *run* the code when you give it a client-side function like plotting or exporting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a pixelwise linear regression across the composited ImageCollection\n",
    "# \"select\" is time and the band you are interested in\n",
    "# The output is the slope of the line fit to each pixel's data over time\n",
    "# and the timestep is \"per year\"\n",
    "trend = yearCompCol.select(['system:time_start_mean', 'NDVI_' + analysis]).reduce(ee.Reducer.linearFit())\n",
    "\n",
    "# 'system:time_start_mean' is my hacky way of doing time per scene\n",
    "# The value is \"the mean number of years since 1970 across the scene\"\n",
    "# which will just be the middle of the month(s) you chose in the year you chose\n",
    "\n",
    "# The result is two outputs: \"scale\" is the slope and \"offset\" is the intercept\n",
    "\n",
    "trend_clip = trend.clip(headwater_sheds)\n",
    "#  Just easier to clip to an Image rather than ImageCollection, and Google doesn't care"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now* we will plot our results! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap.colormaps as cm\n",
    "palette = cm.palettes.ndvi\n",
    "\n",
    "vis_params = {\n",
    "    'min': -0.01,\n",
    "    'max': 0.01,\n",
    "    'palette': palette,\n",
    "}\n",
    "\n",
    "Map.addLayer(trend_clip.select('scale'), vis_params, 'NDVI trend')\n",
    "\n",
    "colors = vis_params['palette']\n",
    "vmin = vis_params['min']\n",
    "vmax = vis_params['max']\n",
    "\n",
    "Map.add_colorbar(vis_params, label='NDVI trend (value/year')\n",
    "\n",
    "Map.addLayerControl()\n",
    "Map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is *so much computation* happening in the blink of an eye!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big data!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, but now we want the *data* itself. But when I say \"data\" remember that the fewer client-side functions you call, the better your code will perform (you can indeed query too much data at a time and Google will say nah in the form of a timeout error). \n",
    "\n",
    "This is where [reducing](https://developers.google.com/earth-engine/guides/reducers_intro) data is crucial (but not obligatory) for your big-data queries. Below I'll show an example of `ee.Reducer.mean()` for our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean pixelwise trend for each watershed\n",
    "basinData = trend.reduceRegions(collection=headwater_sheds,reducer=ee.Reducer.mean(), scale=250)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use `geemap.ee_to_geopandas` which is a *client-side* function and therefore will actually process the code that is so far queued up. Often times you won't get an error message from `ee` until you call a client-side function, which makes debugging challenging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn it into a geodataframe\n",
    "# Rename columns so you know what you did \n",
    "# to_pandas ~ 30 seconds\n",
    "output = geemap.ee_to_geopandas(basinData).rename(columns={\"scale\": analysis+'_trend_slope', \"offset\": analysis+\"_trend_intercept\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For whatever reason the conversion doesn't set a CRS, so I chose WGS84, but it might be Web Mercator (EPSG:3857) like the code editor CRS, not sure :shrug: might have to ask Qiusheng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.set_crs('EPSG:4326') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of plotting, let's grab the centroid of the watershed as the watershed's representative latitude, but there is also the very fun [`gpd.representative_point()'](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoSeries.representative_point.html) that you should try too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['latitude'] = output.centroid.y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trend extracted from GEE with `seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=100)\n",
    "\n",
    "scatter = sns.regplot(\n",
    "    x='latitude',\n",
    "    y='max_trend_slope',\n",
    "    data=output,\n",
    "    scatter_kws={'alpha':0.1,\n",
    "    's':10},\n",
    "     line_kws={'color':'darkgreen', \n",
    "    #  'alpha':0.1,\n",
    "     },\n",
    "     color='green',\n",
    "     ax=ax\n",
    "    )\n",
    "ax.set_ylabel(\"Trend in greening, NDVI/year\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, a statistically significant greening at higher latitudes in our watersheds!\n",
    "\n",
    "Can you think of anything else to play with this data? Maybe a spatial join to the permafrost shapefile? Or maybe some extra data layers from Earth Engine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=200)\n",
    "\n",
    "alaska = permafrost_clipped.to_crs('EPSG:4326').plot(column='EXTENT', alpha=0.5, cmap='cool', legend=True, ax=ax)\n",
    "sheds = output.plot(column='max_trend_slope', cmap='YlGn', ax=ax, legend=True, \n",
    "legend_kwds={'label': \"Greening trend, NDVI/year\",\n",
    "                        'orientation': \"horizontal\"})\n",
    "\n",
    "ax.set_xlim(-180,-125)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get our friends the CALM data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, wouldn't it be cool to have some climate data for our CALM data points? Or any other data for that matter? Let's get on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the calm points into ee\n",
    "calm = geemap.shp_to_ee(\n",
    "    \"CALM_points.shp\",\n",
    "    encoding = \"windows-1254\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab mean annual temperature from the [WorldClim BIO Variables V1](https://developers.google.com/earth-engine/datasets/catalog/WORLDCLIM_V1_BIO) dataset. There are [so many climate datasets](https://developers.google.com/earth-engine/datasets/tags/climate) on Earth Engine you could go wild!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MeanAT = ee.Image('WORLDCLIM/V1/BIO').select('bio01').multiply(0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I read somewhere that if you have point data to save processing time you should use `reduceRegions`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = MeanAT.reduceRegions(\n",
    "        collection = calm, # feature collection here\n",
    "        reducer = ee.Reducer.mean().setOutputs([\"MAT\"]),\n",
    "        scale = 100,\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to bring this into the client side!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = geemap.ee_to_geopandas(stats)\n",
    "extracted.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, some weird reordering of the columns, so if you want to mess around with this data more, remember/fix that!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot `ee`-extracted values for CALM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A little trick: regplot doesn't take hue but scatter does\n",
    "# So layer them!\n",
    "\n",
    "fig, ax = plt.subplots(dpi=100)\n",
    "\n",
    "regression = sns.regplot(\n",
    "    x='MAT',\n",
    "    y='slope',\n",
    "    scatter=False,\n",
    "    data=extracted,\n",
    "    line_kws={'color':'black', \n",
    "     },\n",
    "     ax=ax,\n",
    "    )\n",
    "scatter2 = sns.scatterplot(\n",
    "    x='MAT',\n",
    "    y='slope',\n",
    "    hue='average',\n",
    "    data=extracted,\n",
    "    s=50,\n",
    "    edgecolor='k',\n",
    "    palette=\"Blues_r\",\n",
    "    hue_norm=(25,300), # seaborn's version of vmin and vmax\n",
    "    ax=ax,\n",
    "    zorder=1\n",
    "    )\n",
    "\n",
    "# Some pro tips to make a more useful colorbar for the hue data\n",
    "# https://stackoverflow.com/questions/49761221/make-seaborn-show-a-colorbar-instead-of-a-legend-when-using-hue-in-a-bar-plot\n",
    "norm = plt.Normalize(25,300)\n",
    "sm = plt.cm.ScalarMappable(cmap=\"Blues_r\", norm=norm)\n",
    "sm.set_array([])\n",
    "ax.get_legend().remove()\n",
    "cb = ax.figure.colorbar(sm)\n",
    "cb.set_label(\"Average ALT (cm)\")\n",
    "\n",
    "ax.set_ylabel(\"Average ALT change (cm/yr)\")\n",
    "ax.set_ylim(-2, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So warmer places aren't necessary thawing faster either (since that [confidence interval is 95 percentile by default](https://seaborn.pydata.org/generated/seaborn.regplot.html))...similar to what Sade and I found!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon promt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have the Arctic at your fingertips fam!! Go do science!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neukom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4496227e9e35a1cad8f46d1878e766ce3696b74827c1cccb91d7e0ed1733d2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
